{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import scipy.io\n",
    "from scipy.io import loadmat\n",
    "import spectral\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(358, 200)\n",
      "(1071, 202)\n"
     ]
    }
   ],
   "source": [
    "#加载数据\n",
    "data2 = loadmat('data2_train.mat')[\"data2_train\"]\n",
    "data3 = loadmat('data3_train.mat')[\"data3_train\"]\n",
    "data5 = loadmat('data5_train.mat')[\"data5_train\"]\n",
    "data6 = loadmat('data6_train.mat')[\"data6_train\"]\n",
    "data8 = loadmat('data8_train.mat')[\"data8_train\"]\n",
    "data10 = loadmat('data10_train.mat')[\"data10_train\"]\n",
    "data11 = loadmat('data11_train.mat')[\"data11_train\"]\n",
    "data12 = loadmat('data12_train.mat')[\"data12_train\"]\n",
    "data14 = loadmat('data14_train.mat')[\"data14_train\"]\n",
    "#print(data8.shape)\n",
    "data2 = pd.DataFrame(np.c_[np.arange(data2.shape[0]),data2])\n",
    "data2['label'] = '2'\n",
    "#print(data2.shape)\n",
    "data3 = pd.DataFrame(np.c_[np.arange(data3.shape[0]),data3])\n",
    "data3['label'] = '3'\n",
    "data5 = pd.DataFrame(np.c_[np.arange(data5.shape[0]),data5])\n",
    "data5['label'] = '5'\n",
    "data6 = pd.DataFrame(np.c_[np.arange(data6.shape[0]),data6])\n",
    "data6['label'] = '6'\n",
    "data8 = pd.DataFrame(np.c_[np.arange(data8.shape[0]),data8])\n",
    "data8['label'] = '8'\n",
    "data10= pd.DataFrame(np.c_[np.arange(data10.shape[0]),data10])\n",
    "data10['label'] = '10'\n",
    "data11= pd.DataFrame(np.c_[np.arange(data11.shape[0]),data11])\n",
    "data11['label'] = '11'\n",
    "data12= pd.DataFrame(np.c_[np.arange(data12.shape[0]),data12])\n",
    "data12['label'] = '12'\n",
    "data14= pd.DataFrame(np.c_[np.arange(data14.shape[0]),data14])\n",
    "data14['label'] = '14'\n",
    "data = data2.append(data3)\n",
    "data = data.append(data5)\n",
    "data = data.append(data6)\n",
    "data = data.append(data8)\n",
    "data = data.append(data10)\n",
    "data = data.append(data11)\n",
    "data = data.append(data12)\n",
    "data = data.append(data14)\n",
    "#print(data2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\BaiduNetdiskDownload\\.accelerate\\lib\\site-packages\\sklearn\\utils\\validation.py:475: DataConversionWarning: Data with input dtype object was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    }
   ],
   "source": [
    "#标准化数据并存储\n",
    "new_datawithlabel_array = np.array(data)\n",
    "from sklearn import preprocessing\n",
    "data_D = preprocessing.StandardScaler().fit_transform(new_datawithlabel_array[:,:-1])\n",
    "data_L = new_datawithlabel_array[:,-1]\n",
    "new = np.column_stack((data_D,data_L))\n",
    "new_ = pd.DataFrame(new)\n",
    "new_.to_csv('data.csv',header = False,index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\BaiduNetdiskDownload\\.accelerate\\lib\\site-packages\\ipykernel_launcher.py:9: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "  if __name__ == '__main__':\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10.  6.  2. ... 14. 11. 11.]\n",
      "87.72385904101675\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['MODEL.m']"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#训练模型\n",
    "import joblib\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn import metrics\n",
    "#导入数据集\n",
    "data = pd.read_csv('data.csv',header=None)\n",
    "data = data.as_matrix()\n",
    "data_D = data[:,:-1]\n",
    "data_L = data[:,-1]\n",
    "data_train, data_test, label_train, label_test = train_test_split(data_D,data_L,test_size=0.5)\n",
    "# 模型训练与拟合\n",
    "clf = SVC(kernel='rbf',gamma=0.125,C=16)\n",
    "clf.fit(data_train,label_train)\n",
    "pred = clf.predict(data_test)\n",
    "#print(pred)\n",
    "#print(data_test.shape)\n",
    "accuracy = metrics.accuracy_score(label_test, pred)*100\n",
    "print (accuracy)\n",
    "# 存储结果学习模型，方便之后的调用\n",
    "joblib.dump(clf, \"MODEL.m\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2310, 200)\n",
      "(2310, 202)\n",
      "(2310, 201)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\BaiduNetdiskDownload\\.accelerate\\lib\\site-packages\\sklearn\\utils\\validation.py:475: DataConversionWarning: Data with input dtype object was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    }
   ],
   "source": [
    "#预测\n",
    "data_test_final = loadmat('data_test_final.mat')[\"data_test_final\"]\n",
    "print(data_test_final.shape)\n",
    "data_test_final = pd.DataFrame(np.c_[np.arange(data_test_final.shape[0]),data_test_final])\n",
    "data_test_final['label'] = '0'\n",
    "print(data_test_final.shape)\n",
    "data_test_final = np.array(data_test_final)\n",
    "data_test_final = preprocessing.StandardScaler().fit_transform(data_test_final[:,:-1])\n",
    "print(data_test_final.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          id     y\n",
      "0        0.0   2.0\n",
      "1        1.0  14.0\n",
      "2        2.0   3.0\n",
      "3        3.0   2.0\n",
      "4        4.0  11.0\n",
      "5        5.0   2.0\n",
      "6        6.0   2.0\n",
      "7        7.0  12.0\n",
      "8        8.0  12.0\n",
      "9        9.0  14.0\n",
      "10      10.0   2.0\n",
      "11      11.0  11.0\n",
      "12      12.0   2.0\n",
      "13      13.0   2.0\n",
      "14      14.0   2.0\n",
      "15      15.0  10.0\n",
      "16      16.0   2.0\n",
      "17      17.0   2.0\n",
      "18      18.0   2.0\n",
      "19      19.0   2.0\n",
      "20      20.0   2.0\n",
      "21      21.0   2.0\n",
      "22      22.0  14.0\n",
      "23      23.0   2.0\n",
      "24      24.0   2.0\n",
      "25      25.0   2.0\n",
      "26      26.0   2.0\n",
      "27      27.0   5.0\n",
      "28      28.0  14.0\n",
      "29      29.0   2.0\n",
      "...      ...   ...\n",
      "2280  2280.0   2.0\n",
      "2281  2281.0  11.0\n",
      "2282  2282.0   2.0\n",
      "2283  2283.0   2.0\n",
      "2284  2284.0  11.0\n",
      "2285  2285.0   2.0\n",
      "2286  2286.0  11.0\n",
      "2287  2287.0  14.0\n",
      "2288  2288.0  11.0\n",
      "2289  2289.0   2.0\n",
      "2290  2290.0   2.0\n",
      "2291  2291.0   2.0\n",
      "2292  2292.0   2.0\n",
      "2293  2293.0  14.0\n",
      "2294  2294.0   2.0\n",
      "2295  2295.0  11.0\n",
      "2296  2296.0   2.0\n",
      "2297  2297.0  11.0\n",
      "2298  2298.0   2.0\n",
      "2299  2299.0   2.0\n",
      "2300  2300.0  11.0\n",
      "2301  2301.0  11.0\n",
      "2302  2302.0  11.0\n",
      "2303  2303.0   2.0\n",
      "2304  2304.0   2.0\n",
      "2305  2305.0   2.0\n",
      "2306  2306.0  11.0\n",
      "2307  2307.0  14.0\n",
      "2308  2308.0   2.0\n",
      "2309  2309.0   2.0\n",
      "\n",
      "[2310 rows x 2 columns]\n"
     ]
    },
    {
     "ename": "PermissionError",
     "evalue": "[Errno 13] Permission denied: 'y_predict.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mPermissionError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-61-6a9fc931176f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0my_predict\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mc_\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_predict\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_predict\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'id'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'y'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_predict\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0my_predict\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'y_predict.csv'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mF:\\BaiduNetdiskDownload\\.accelerate\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36mto_csv\u001b[1;34m(self, path_or_buf, sep, na_rep, float_format, columns, header, index, index_label, mode, encoding, compression, quoting, quotechar, line_terminator, chunksize, tupleize_cols, date_format, doublequote, escapechar, decimal)\u001b[0m\n\u001b[0;32m   1743\u001b[0m                                  \u001b[0mdoublequote\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdoublequote\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1744\u001b[0m                                  escapechar=escapechar, decimal=decimal)\n\u001b[1;32m-> 1745\u001b[1;33m         \u001b[0mformatter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1746\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1747\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mpath_or_buf\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mF:\\BaiduNetdiskDownload\\.accelerate\\lib\\site-packages\\pandas\\io\\formats\\csvs.py\u001b[0m in \u001b[0;36msave\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    134\u001b[0m             f, handles = _get_handle(self.path_or_buf, self.mode,\n\u001b[0;32m    135\u001b[0m                                      \u001b[0mencoding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mencoding\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 136\u001b[1;33m                                      compression=None)\n\u001b[0m\u001b[0;32m    137\u001b[0m             \u001b[0mclose\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompression\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    138\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mF:\\BaiduNetdiskDownload\\.accelerate\\lib\\site-packages\\pandas\\io\\common.py\u001b[0m in \u001b[0;36m_get_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text)\u001b[0m\n\u001b[0;32m    398\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0mencoding\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    399\u001b[0m             \u001b[1;31m# Python 3 and encoding\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 400\u001b[1;33m             \u001b[0mf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath_or_buf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mencoding\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    401\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0mis_text\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    402\u001b[0m             \u001b[1;31m# Python 3 and no explicit encoding\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mPermissionError\u001b[0m: [Errno 13] Permission denied: 'y_predict.csv'"
     ]
    }
   ],
   "source": [
    "clf = joblib.load('MODEL.m')\n",
    "y_predict = clf.predict(data_test_final)\n",
    "y_predict = pd.DataFrame(np.c_[np.arange(y_predict.shape[0]),y_predict],columns=['id','y'])\n",
    "print(y_predict)\n",
    "y_predict.to_csv('y_predict.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
